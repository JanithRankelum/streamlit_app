{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIF3tOMNz5DuNl647gjl9/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanithRankelum/streamlit_app/blob/master/app_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_iaAM-uHqmn"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import boto3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from io import StringIO, BytesIO\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import json\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import plotly.express as px\n",
        "\n",
        "# AWS Configuration\n",
        "BUCKET_NAME = 'riceprice-s3-bucket'\n",
        "FILE_PATH = '/content/drive/MyDrive/cleaned_data.csv'\n",
        "KINESIS_STREAM_NAME = 'rice-price-stream'  # Only used if stream exists\n",
        "\n",
        "# Initialize AWS clients\n",
        "s3 = boto3.client('s3')\n",
        "kinesis = boto3.client('kinesis')\n",
        "lambda_client = boto3.client('lambda')\n",
        "\n",
        "# Check if Kinesis stream exists\n",
        "def kinesis_stream_exists(stream_name):\n",
        "    try:\n",
        "        kinesis.describe_stream(StreamName=stream_name)\n",
        "        return True\n",
        "    except kinesis.exceptions.ResourceNotFoundException:\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error checking Kinesis stream: {e}\")\n",
        "        return False\n",
        "\n",
        "# Function to upload data to S3 (and optionally Kinesis)\n",
        "def upload_data(file_path, bucket_name):\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "        s3_file_name = f'rice_prices_{timestamp}.csv'\n",
        "        s3.upload_file(file_path, bucket_name, s3_file_name)\n",
        "\n",
        "        if kinesis_stream_exists(KINESIS_STREAM_NAME):\n",
        "            df = pd.read_csv(file_path)\n",
        "            for _, row in df.iterrows():\n",
        "                record = {\n",
        "                    'timestamp': str(datetime.now()),\n",
        "                    'province': row['province'],\n",
        "                    'price': float(row['price'])\n",
        "                }\n",
        "                kinesis.put_record(\n",
        "                    StreamName=KINESIS_STREAM_NAME,\n",
        "                    Data=json.dumps(record),\n",
        "                    PartitionKey=row['province']\n",
        "                )\n",
        "            st.success(f\"Uploaded {file_path} to S3 and Kinesis\")\n",
        "        else:\n",
        "            st.success(f\"Uploaded {file_path} to S3 (Kinesis stream not found)\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error uploading file: {e}\")\n",
        "\n",
        "@st.cache_data(ttl=60)\n",
        "def read_processed_data(bucket_name):\n",
        "    try:\n",
        "        processed_key = 'processed_data/latest.parquet'\n",
        "        obj = s3.get_object(Bucket=bucket_name, Key=processed_key)\n",
        "        return pd.read_parquet(BytesIO(obj['Body'].read()))\n",
        "    except:\n",
        "        try:\n",
        "            response = s3.list_objects_v2(Bucket=bucket_name)\n",
        "            if 'Contents' not in response:\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            latest_file = max(response['Contents'], key=lambda x: x['LastModified'])\n",
        "            file_key = latest_file['Key']\n",
        "            response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
        "            csv_data = response['Body'].read().decode('utf-8')\n",
        "            df = pd.read_csv(StringIO(csv_data))\n",
        "\n",
        "            if 'date' in df.columns:\n",
        "                df['date'] = pd.to_datetime(df['date'])\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error reading data: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "def detect_anomalies(df):\n",
        "    if len(df) == 0:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df = df.copy()\n",
        "    df['z_score'] = (df['price'] - df['price'].mean()) / df['price'].std()\n",
        "    df['abs_z_score'] = np.abs(df['z_score'])\n",
        "\n",
        "    model = IsolationForest(contamination=0.05)\n",
        "    df['ml_anomaly'] = model.fit_predict(df[['price']].values) == -1\n",
        "    df['is_anomaly'] = (df['abs_z_score'] > 2.5) | df['ml_anomaly']\n",
        "\n",
        "    return df\n",
        "\n",
        "def calculate_trends(df):\n",
        "    if len(df) == 0:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df = df.sort_values('date')\n",
        "    df['3_day_ma'] = df['price'].rolling(window=3).mean()\n",
        "    df['7_day_ma'] = df['price'].rolling(window=7).mean()\n",
        "    df['trend'] = np.where(df['3_day_ma'] > df['7_day_ma'], 'Upward', 'Downward')\n",
        "\n",
        "    return df\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"Rice Price Monitoring Dashboard\")\n",
        "\n",
        "with st.sidebar:\n",
        "    st.header(\"Controls\")\n",
        "    refresh_rate = st.slider(\"Refresh rate (seconds)\", 10, 300, 60)\n",
        "    anomaly_threshold = st.slider(\"Anomaly sensitivity\", 1.0, 5.0, 2.5, 0.1)\n",
        "\n",
        "    if st.button(\"Upload New Data\"):\n",
        "        upload_data(FILE_PATH, BUCKET_NAME)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"**System Status:**\")\n",
        "    st.markdown(f\"- S3 Bucket: `{BUCKET_NAME}`\")\n",
        "    st.markdown(f\"- Kinesis Stream: {'Found' if kinesis_stream_exists(KINESIS_STREAM_NAME) else 'Not found'}\")\n",
        "\n",
        "    # st.markdown(\"**Next Steps:**\")\n",
        "    # st.markdown(\"- Spark integration for large datasets\")\n",
        "    # st.markdown(\"- Weather data correlation\")\n",
        "    # st.markdown(\"- Predictive analytics\")\n",
        "\n",
        "tab1, tab2, tab3 = st.tabs([\"Overview\", \"Trend Analysis\", \"Anomaly Detection\"])\n",
        "\n",
        "data = read_processed_data(BUCKET_NAME)\n",
        "if not data.empty:\n",
        "    data = calculate_trends(data)\n",
        "    data = detect_anomalies(data)\n",
        "\n",
        "    with tab1:\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.subheader(\"Current Market Status\")\n",
        "            latest_date = data['date'].max()\n",
        "            latest_data = data[data['date'] == latest_date]\n",
        "\n",
        "            if not latest_data.empty:\n",
        "                avg_price = latest_data['price'].mean()\n",
        "                prev_avg = data[data['date'] < latest_date]['price'].mean() if len(data) > 10 else 0\n",
        "                delta = avg_price - prev_avg\n",
        "                st.metric(\n",
        "                    f\"National Average Price ({latest_date.strftime('%Y-%m-%d')})\",\n",
        "                    f\"LKR {avg_price:.2f}\",\n",
        "                    f\"{delta:+.2f} vs prior period\" if len(data) > 10 else \"Insufficient data\"\n",
        "                )\n",
        "            else:\n",
        "                st.warning(\"No recent price data available.\")\n",
        "\n",
        "            st.plotly_chart(\n",
        "                px.line(\n",
        "                    data,\n",
        "                    x='date',\n",
        "                    y='price',\n",
        "                    title=\"Price Movement\"\n",
        "                ),\n",
        "                use_container_width=True\n",
        "            )\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"Provincial Overview\")\n",
        "            st.plotly_chart(\n",
        "                px.bar(\n",
        "                    data.groupby('province')['price'].mean().reset_index(),\n",
        "                    x='province',\n",
        "                    y='price',\n",
        "                    title=\"Average Prices by Province\"\n",
        "                ),\n",
        "                use_container_width=True\n",
        "            )\n",
        "\n",
        "    with tab2:\n",
        "        st.subheader(\"Detailed Trend Analysis\")\n",
        "        trend_col1, trend_col2 = st.columns(2)\n",
        "\n",
        "        with trend_col1:\n",
        "            st.plotly_chart(\n",
        "                px.line(\n",
        "                    data.set_index('date')[['price', '3_day_ma', '7_day_ma']].reset_index(),\n",
        "                    x='date',\n",
        "                    y=['price', '3_day_ma', '7_day_ma'],\n",
        "                    title=\"Price with Moving Averages\"\n",
        "                ),\n",
        "                use_container_width=True\n",
        "            )\n",
        "\n",
        "        with trend_col2:\n",
        "            st.plotly_chart(\n",
        "                px.histogram(\n",
        "                    data,\n",
        "                    x='trend',\n",
        "                    title=\"Trend Direction Distribution\"\n",
        "                ),\n",
        "                use_container_width=True\n",
        "            )\n",
        "\n",
        "    with tab3:\n",
        "        st.subheader(\"Anomaly Detection Center\")\n",
        "        anomalies = data[data['is_anomaly']]\n",
        "\n",
        "        if not anomalies.empty:\n",
        "            alert_col1, alert_col2 = st.columns(2)\n",
        "\n",
        "            with alert_col1:\n",
        "                fig = px.scatter(\n",
        "                    anomalies,\n",
        "                    x='date',\n",
        "                    y='price',\n",
        "                    color='province',\n",
        "                    size='abs_z_score',\n",
        "                    title=\"Detected Anomalies\",\n",
        "                    hover_data=['z_score']\n",
        "                )\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            with alert_col2:\n",
        "                st.dataframe(\n",
        "                    anomalies[['date', 'province', 'price', 'z_score']].sort_values('z_score', ascending=False),\n",
        "                    height=400\n",
        "                )\n",
        "\n",
        "            st.warning(f\"ðŸš¨ {len(anomalies)} anomalies detected in current data window\")\n",
        "        else:\n",
        "            st.success(\"No anomalies detected in current data window\")\n",
        "\n",
        "else:\n",
        "    st.warning(\"No data available in S3 bucket\")\n",
        "\n",
        "last_refresh = st.empty()\n",
        "last_refresh.text(f\"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    }
  ]
}